# Implementation Submission Description
https://docs.google.com/document/d/1_WtcIEK9NZbwHpl8Ubc147YtbOsQDxEGr36g5S8PsCQ/edit?tab=t.0#heading=h.rgiyidgnbo62

# Implementation Plan

This project is structured into two main components:

1. `ml_evaluation/` â€” Responsible for model training, LLM-enhanced feature engineering, and performance evaluation.

2. `web_app/` â€” A fullstack web application for interactive visualization and explanation using model predictions and LLM output.

---


## ğŸ“ data/

```
data/
â”œâ”€â”€ csv/                        # Compressed CSV files of crime incidents
â”‚   â””â”€â”€ sf_crime_YYYYMMDD_YYYYMMDD.csv.gz  # Date range in filename
â”œâ”€â”€ mongodb/                    # MongoDB data directory
â”‚  
â””â”€â”€ external/                  # External data sources for context
   
```


---

## ğŸ“ data_preprocessing/

```
data_preprocessing/
â”œâ”€â”€ crime_data_pipeline.py      # Main pipeline for fetching and processing crime data
â””â”€â”€ view_crime_data.py         # Utility for viewing processed crime data
```

### Setup and Usage

1. **MongoDB Setup**
   ```zsh
   # Create MongoDB data directory
   mkdir -p data/mongodb
   
   # Start MongoDB server (run in background)
   mongod --dbpath data/mongodb &
   ```

2. **Data Pipeline Execution**
   ```zsh
   # Run the main data pipeline
   python3 data_preprocessing/crime_data_pipeline.py
   
   # View processed data
   python3 data_preprocessing/view_crime_data.py
   ```



---

## ğŸ“ ml_evaluation/

```
ml_evaluation/
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks for EDA and prototyping
â”‚   â”œâ”€â”€ 01_explore.ipynb        # Explore data distribution, spatial & temporal patterns
â”‚   â”œâ”€â”€ 02_rf_model.ipynb       # Build and tune Random Forest baseline
â”‚   â””â”€â”€ 03_llm_feature_gen.ipynb# Prototype LLM-based feature generation
â”‚
â”œâ”€â”€ utils/                      # Utility functions for preprocessing, metrics, configs
â”‚   â”œâ”€â”€ preprocessing.py        # Data cleaning, time formatting, missing value handling
â”‚   â”œâ”€â”€ config.py               # Global paths, constants, model parameters
â”‚   â””â”€â”€ metrics.py              # Custom evaluation metrics (e.g., F1 score, confusion matrix)
â”‚
â”œâ”€â”€ baseline_rf.py              # Random Forest training on structured features
â”œâ”€â”€ llm_features.py             # LLM-assisted feature engineering module (e.g., event tags, imputation)
â”œâ”€â”€ evaluate_models.py          # Run both models, compare accuracy, generate results
â”œâ”€â”€ results/                    # Output folder for model predictions and evaluation visualizations
```

---

## ğŸ“ web_app/

```
web_app/
â”œâ”€â”€ backend/                    # FastAPI server that connects model output and LLM explanations
â”‚   â”œâ”€â”€ app.py                  # Entry point for running the FastAPI app
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ prediction.py       # API endpoint to serve model predictions
â”‚   â”‚   â””â”€â”€ explanation.py      # API endpoint to serve LLM-generated explanations
â”‚   â””â”€â”€ utils/                  # Helper functions for loading models and formatting responses
â”‚
â”œâ”€â”€ frontend/                   # Frontend interface using HTML, JS (e.g., D3.js or React)
â”‚   â”œâ”€â”€ index.html              # Web page structure
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ map.js              # Map-based crime visualization
â”‚   â”‚   â””â”€â”€ panel.js            # Narrative panel for LLM-generated summaries
â”‚   â””â”€â”€ style.css               # Styling for layout, components, and map
```


---

## ğŸ“„ Supporting Files

```
requirements.txt               # Python dependencies for ML, API, and LLM
README.md                      # Project overview, setup guide, usage instructions
Implementation_Plan.md         # This document: file structure and purpose overview
.env (copy .env.example)
```
